{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11837923,"sourceType":"datasetVersion","datasetId":7437462}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\n!pip install opencv-python\n!pip install matplotlib\n!pip install tqdm\n!pip install pillow\n!pip install pyyaml\n!pip install seaborn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T16:29:18.515661Z","iopub.execute_input":"2025-05-16T16:29:18.516074Z","iopub.status.idle":"2025-05-16T16:30:50.814568Z","shell.execute_reply.started":"2025-05-16T16:29:18.516055Z","shell.execute_reply":"2025-05-16T16:30:50.813610Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.136-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.136-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.136 ultralytics-thop-2.0.14\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport shutil\nimport random\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nfrom datetime import datetime\nfrom PIL import Image\n\n# BDD100K Dataset paths\nBASE_DIR = \"/kaggle/working/vehicle_pedestrian_detection_yolo\"\nORIGINAL_DS_DIR = \"/kaggle/input/bdd-dataset-100k\"  # Base BDD100K directory\nIMAGES_DIR = os.path.join(ORIGINAL_DS_DIR, \"bdd100k\", \"images\", \"100k\")\nTRAIN_IMAGES = os.path.join(IMAGES_DIR, \"train\")\nVAL_IMAGES = os.path.join(IMAGES_DIR, \"val\")\nANNOTATIONS_FILE = os.path.join(ORIGINAL_DS_DIR, \"labels\", \"bdd100k_labels_images_train.json\")\nVAL_ANNOTATIONS_FILE = os.path.join(ORIGINAL_DS_DIR, \"labels\", \"bdd100k_labels_images_val.json\")\n\nDATASET_DIR = os.path.join(BASE_DIR, \"dataset\")\n\nEPOCHS = 30\nBATCH_SIZE = 32\nWORKERS = 8\nIMG_SIZE = (640, 640)\nYOLO_MODEL_SIZE = \"yolov8l.pt\"\nCONF_THRESHOLD = 0.25\n\nos.makedirs(os.path.join(DATASET_DIR, \"images\", \"train\"), exist_ok=True)\nos.makedirs(os.path.join(DATASET_DIR, \"images\", \"val\"), exist_ok=True)\nos.makedirs(os.path.join(DATASET_DIR, \"labels\", \"train\"), exist_ok=True)\nos.makedirs(os.path.join(DATASET_DIR, \"labels\", \"val\"), exist_ok=True)\n\nprint(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    device = '0'\n    os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\nelse:\n    print(\"No CUDA devices available, using CPU\")\n    device = 'cpu'\n\ndef load_bdd100k_annotations(annotation_file):\n    print(f\"Loading annotations from {annotation_file}\")\n    try:\n        with open(annotation_file, 'r') as f:\n            annotations = json.load(f)\n        print(f\"Loaded annotations for {len(annotations)} images\")\n        return annotations\n    except Exception as e:\n        print(f\"Error loading annotations: {e}\")\n        return []\n\ndef extract_class_mapping(annotations):\n    unique_categories = set()\n    \n    print(\"Scanning for unique object categories...\")\n    for img_anno in tqdm(annotations):\n        for label in img_anno.get(\"labels\", []):\n            category = label.get(\"category\")\n            if category:\n                unique_categories.add(category)\n    \n    sorted_categories = sorted(list(unique_categories))\n    category_to_id = {category: i for i, category in enumerate(sorted_categories)}\n    \n    print(f\"Found {len(sorted_categories)} unique categories: {sorted_categories}\")\n    return category_to_id, sorted_categories\n\ndef convert_bdd100k_to_yolo(image_file, annotations, category_to_id):\n    img_name = os.path.basename(image_file)\n    \n    img_anno = None\n    for anno in annotations:\n        if anno.get(\"name\") == img_name:\n            img_anno = anno\n            break\n    \n    if not img_anno:\n        return []\n\n    try:\n        with Image.open(image_file) as img:\n            img_width, img_height = img.size\n    except Exception as e:\n        print(f\"Error reading image {image_file}: {e}\")\n        return []\n    \n    yolo_annotations = []\n    \n    for label in img_anno.get(\"labels\", []):\n        category = label.get(\"category\")\n        if category not in category_to_id:\n            continue\n        \n        box = label.get(\"box2d\")\n        if not box:\n            continue\n        \n        xmin = float(box[\"x1\"])\n        ymin = float(box[\"y1\"])\n        xmax = float(box[\"x2\"])\n        ymax = float(box[\"y2\"])\n        \n        x_center = (xmin + xmax) / 2 / img_width\n        y_center = (ymin + ymax) / 2 / img_height\n        width = (xmax - xmin) / img_width\n        height = (ymax - ymin) / img_height\n        \n        if width <= 0 or height <= 0 or not all(0 <= val <= 1 for val in [x_center, y_center, width, height]):\n            continue\n        \n        class_id = category_to_id[category]\n        yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n    \n    return yolo_annotations\n\ndef find_all_training_images():\n    all_images = []\n    \n    subdirs = [d for d in os.listdir(TRAIN_IMAGES) if os.path.isdir(os.path.join(TRAIN_IMAGES, d))]\n    \n    if subdirs and subdirs[0].startswith('train'):\n        print(f\"Found training subdirectories: {subdirs}\")\n        for subdir in subdirs:\n            subdir_path = os.path.join(TRAIN_IMAGES, subdir)\n            for ext in ['*.jpg', '*.jpeg', '*.png']:\n                all_images.extend(glob.glob(os.path.join(subdir_path, ext)))\n    else:\n        for ext in ['*.jpg', '*.jpeg', '*.png']:\n            all_images.extend(glob.glob(os.path.join(TRAIN_IMAGES, ext)))\n    \n    print(f\"Found {len(all_images)} training images\")\n    return all_images\n\ndef find_all_validation_images():\n    all_images = []\n    \n    for ext in ['*.jpg', '*.jpeg', '*.png']:\n        all_images.extend(glob.glob(os.path.join(VAL_IMAGES, ext)))\n    \n    print(f\"Found {len(all_images)} validation images\")\n    return all_images\n\ndef prepare_dataset():\n    print(\"Loading annotations...\")\n    train_annotations = load_bdd100k_annotations(ANNOTATIONS_FILE)\n    val_annotations = load_bdd100k_annotations(VAL_ANNOTATIONS_FILE)\n    \n    if not train_annotations:\n        print(\"ERROR: No training annotations found!\")\n        return None\n    \n    print(\"Extracting class mapping...\")\n    category_to_id, class_names = extract_class_mapping(train_annotations + val_annotations)\n    \n    print(\"Finding training images...\")\n    train_images = find_all_training_images()\n    \n    print(\"Finding validation images...\")\n    val_images = find_all_validation_images()\n    \n    print(\"Processing training set...\")\n    train_with_labels = 0\n    for img_path in tqdm(train_images):\n        img_name = os.path.basename(img_path)\n        dest_img = os.path.join(DATASET_DIR, \"images\", \"train\", img_name)\n        \n        shutil.copy2(img_path, dest_img)\n        \n        yolo_annotations = convert_bdd100k_to_yolo(img_path, train_annotations, category_to_id)\n        if yolo_annotations:\n            label_name = os.path.splitext(img_name)[0] + \".txt\"\n            label_path = os.path.join(DATASET_DIR, \"labels\", \"train\", label_name)\n            with open(label_path, 'w') as f:\n                f.write(\"\\n\".join(yolo_annotations))\n            train_with_labels += 1\n    \n    print(\"Processing validation set...\")\n    val_with_labels = 0\n    for img_path in tqdm(val_images):\n        img_name = os.path.basename(img_path)\n        dest_img = os.path.join(DATASET_DIR, \"images\", \"val\", img_name)\n        \n        shutil.copy2(img_path, dest_img)\n        \n        yolo_annotations = convert_bdd100k_to_yolo(img_path, val_annotations, category_to_id)\n        if yolo_annotations:\n            label_name = os.path.splitext(img_name)[0] + \".txt\"\n            label_path = os.path.join(DATASET_DIR, \"labels\", \"val\", label_name)\n            with open(label_path, 'w') as f:\n                f.write(\"\\n\".join(yolo_annotations))\n            val_with_labels += 1\n    \n    print(\"Creating dataset.yaml...\")\n    dataset_yaml_path = os.path.join(DATASET_DIR, \"dataset.yaml\")\n    with open(dataset_yaml_path, \"w\") as f:\n        f.write(f\"train: ./images/train\\n\")\n        f.write(f\"val: ./images/val\\n\")\n        f.write(f\"nc: {len(class_names)}\\n\")\n        f.write(f\"names: {class_names}\\n\")\n    \n    train_imgs = glob.glob(os.path.join(DATASET_DIR, \"images\", \"train\", \"*.*\"))\n    val_imgs = glob.glob(os.path.join(DATASET_DIR, \"images\", \"val\", \"*.*\"))\n    train_labels = glob.glob(os.path.join(DATASET_DIR, \"labels\", \"train\", \"*.txt\"))\n    val_labels = glob.glob(os.path.join(DATASET_DIR, \"labels\", \"val\", \"*.txt\"))\n    \n    print(\"\\nDataset prepared:\")\n    print(f\"  Training images: {len(train_imgs)} ({train_with_labels} with labels)\")\n    print(f\"  Training labels: {len(train_labels)}\")\n    print(f\"  Validation images: {len(val_imgs)} ({val_with_labels} with labels)\")\n    print(f\"  Validation labels: {len(val_labels)}\")\n    print(f\"  Categories: {len(class_names)}\")\n    print(f\"  Classes: {', '.join(class_names)}\")\n    \n    return dataset_yaml_path\n\ndef train_model(dataset_yaml_path):\n    print(\"\\nInitializing YOLOv8 model...\")\n    try:\n        model = YOLO(YOLO_MODEL_SIZE)\n        print(\"Model loaded successfully\")\n    except Exception as e:\n        print(f\"Error loading model: {e}\")\n        print(\"Downloading model using torch hub...\")\n        torch.hub.load('ultralytics/yolov8', 'yolov8l', pretrained=True)\n        model = YOLO(YOLO_MODEL_SIZE)\n    \n    print(\"\\nStarting training...\")\n    os.chdir(DATASET_DIR)\n    \n    results = model.train(\n        data=dataset_yaml_path,\n        epochs=EPOCHS,\n        workers=WORKERS,\n        imgsz=IMG_SIZE,\n        batch=BATCH_SIZE,\n        name='yolo_bdd100k_detector',\n        patience=15,\n        save=True,\n        device=device,\n        cache=False,\n        amp=True,\n        rect=True,\n        plots=True,\n        augment=True,\n        close_mosaic=10,\n        overlap_mask=True,\n        cos_lr=True,\n        pretrained=True,\n        seed=42,\n        profile=True,\n        verbose=True,\n        mosaic=0.8,\n        mixup=0.1,\n        copy_paste=0.1,\n        degrees=10.0,\n        scale=0.5,\n        save_period=10\n    )\n    \n    print(\"\\nValidating trained model...\")\n    best_model_path = os.path.join(\"runs\", \"detect\", \"yolo_bdd100k_detector\", \"weights\", \"best.pt\")\n    \n    metrics = model.val(\n        data=dataset_yaml_path,\n        conf=CONF_THRESHOLD\n    )\n    \n    kaggle_output_path = \"/kaggle/working/bdd100k_detector_best.pt\"\n    \n    print(\"\\nEvaluating model performance...\")\n    evaluate_detection_model(\n        model_path=best_model_path,\n        data_yaml=dataset_yaml_path,\n        conf_threshold=CONF_THRESHOLD,\n        iou_threshold=0.5,\n        save_dir=\"/kaggle/working/detection_metrics\"\n    )\n    \n    shutil.copy2(best_model_path, kaggle_output_path)\n    print(f\"Model saved to Kaggle working directory: {kaggle_output_path}\")\n    \n    # Save the results images\n    results_img = f\"runs/detect/yolo_bdd100k_detector/results.png\"\n    confusion_matrix = f\"runs/detect/yolo_bdd100k_detector/confusion_matrix.png\"\n    \n    if os.path.exists(results_img):\n        shutil.copy2(results_img, \"/kaggle/working/results.png\")\n    if os.path.exists(confusion_matrix):\n        shutil.copy2(confusion_matrix, \"/kaggle/working/confusion_matrix.png\")\n    \n    print(\"\\nTraining and evaluation complete!\")\n\ndef evaluate_detection_model(model_path, data_yaml, conf_threshold=0.25, iou_threshold=0.5, save_dir=\"metrics\"):\n    os.makedirs(save_dir, exist_ok=True)\n    \n    model = YOLO(model_path)\n    \n    metrics = model.val(\n        data=data_yaml,\n        conf=conf_threshold,\n        iou=iou_threshold,\n        verbose=True,\n        save_json=True,\n        save_hybrid=True,\n        plots=True\n    )\n    \n    results = {\n        \"mAP50\": float(metrics.box.map50),\n        \"mAP50-95\": float(metrics.box.map),\n        \"precision\": float(metrics.box.mp),\n        \"recall\": float(metrics.box.mr),\n        \"f1\": float(2 * metrics.box.mp * metrics.box.mr / (metrics.box.mp + metrics.box.mr + 1e-10)),\n        \"conf_threshold\": conf_threshold,\n        \"iou_threshold\": iou_threshold,\n        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    }\n    \n    per_class_ap = {}\n    if hasattr(metrics.box, 'ap_class_index') and hasattr(metrics.box, 'ap50'):\n        class_names = model.names\n        for i, class_idx in enumerate(metrics.box.ap_class_index):\n            class_name = class_names[int(class_idx)]\n            per_class_ap[class_name] = float(metrics.box.ap50[i])\n        results[\"per_class_ap50\"] = per_class_ap\n    \n    with open(os.path.join(save_dir, f\"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"), 'w') as f:\n        json.dump(results, f, indent=4)\n    \n    print(\"\\n===== BDD100K DETECTION MODEL EVALUATION =====\")\n    print(f\"mAP@0.5: {results['mAP50']:.4f}\")\n    print(f\"mAP@0.5:0.95: {results['mAP50-95']:.4f}\")\n    print(f\"Precision: {results['precision']:.4f}\")\n    print(f\"Recall: {results['recall']:.4f}\")\n    print(f\"F1 Score: {results['f1']:.4f}\")\n    \n    if \"per_class_ap50\" in results:\n        print(\"\\nPer-class AP@0.5:\")\n        for class_name, ap in results[\"per_class_ap50\"].items():\n            print(f\"  {class_name}: {ap:.4f}\")\n    \n    return results\n\nif __name__ == \"__main__\":\n    dataset_yaml_path = prepare_dataset()\n    if dataset_yaml_path:\n        train_model(dataset_yaml_path)\n    else:\n        print(\"Dataset preparation failed. Exiting.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T16:54:05.713373Z","iopub.execute_input":"2025-05-16T16:54:05.714467Z","iopub.status.idle":"2025-05-16T18:45:01.135121Z","shell.execute_reply.started":"2025-05-16T16:54:05.714432Z","shell.execute_reply":"2025-05-16T18:45:01.134393Z"}},"outputs":[{"name":"stdout","text":"PyTorch CUDA available: True\nGPU: Tesla P100-PCIE-16GB\nLoading annotations...\nLoading annotations from /kaggle/input/bdd-dataset-100k/labels/bdd100k_labels_images_train.json\nLoaded annotations for 69863 images\nLoading annotations from /kaggle/input/bdd-dataset-100k/labels/bdd100k_labels_images_val.json\nLoaded annotations for 10000 images\nExtracting class mapping...\nScanning for unique object categories...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79863/79863 [00:00<00:00, 226664.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Found 12 unique categories: ['bike', 'bus', 'car', 'drivable area', 'lane', 'motor', 'person', 'rider', 'traffic light', 'traffic sign', 'train', 'truck']\nFinding training images...\nFound 1156 training images\nFinding validation images...\nFound 10000 validation images\nProcessing training set...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1156/1156 [00:16<00:00, 69.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing validation set...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [01:27<00:00, 114.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Creating dataset.yaml...\n\nDataset prepared:\n  Training images: 1156 (1154 with labels)\n  Training labels: 1154\n  Validation images: 10000 (10000 with labels)\n  Validation labels: 10000\n  Categories: 12\n  Classes: bike, bus, car, drivable area, lane, motor, person, rider, traffic light, traffic sign, train, truck\n\nInitializing YOLOv8 model...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.7M/83.7M [00:00<00:00, 334MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully\n\nStarting training...\nUltralytics 8.3.136 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/vehicle_pedestrian_detection_yolo/dataset/dataset.yaml, degrees=10.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=(640, 640), int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=0.8, multi_scale=False, name=yolo_bdd100k_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=True, project=None, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/yolo_bdd100k_detector, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 28.9MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=12\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5592052  ultralytics.nn.modules.head.Detect           [12, [256, 512, 512]]         \nModel summary: 209 layers, 43,639,092 parameters, 43,639,076 gradients, 165.5 GFLOPs\n\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 114MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\nWARNING âš ï¸ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 848.7Â±631.0 MB/s, size: 46.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/train... 1154 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1156/1156 [00:00<00:00, 1199.21it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/train.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\nWARNING âš ï¸ 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 749.3Â±272.6 MB/s, size: 41.1 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:09<00:00, 1086.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/val.cache\nPlotting labels to runs/detect/yolo_bdd100k_detector/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/yolo_bdd100k_detector\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/30         2G      1.709      2.178      1.239         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [01:47<00:00,  2.90s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:43<00:00,  1.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.386      0.235      0.198     0.0966\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/30      11.6G      1.635      1.279      1.223         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.02s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:24<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.174      0.152      0.113     0.0485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/30      11.3G      1.651      1.242      1.235         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.267      0.121     0.0877     0.0376\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/30      11.9G      1.692      1.249      1.257         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:26<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.321      0.153     0.0625     0.0274\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/30      11.7G      1.686      1.235      1.258         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:26<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.314      0.202      0.144     0.0594\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/30        12G      1.638      1.172      1.229         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.469      0.216      0.182     0.0794\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/30      11.7G      1.621      1.147      1.219         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.301      0.226      0.195     0.0875\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/30        12G      1.607      1.129      1.205         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.322      0.236      0.204     0.0958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/30      11.3G      1.581      1.079      1.194         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.386      0.242      0.216        0.1\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/30      11.4G      1.557      1.053       1.18         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.414      0.256       0.23      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/30      11.3G      1.541      1.025      1.164         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.377      0.264      0.244      0.119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/30      11.4G      1.523      1.001      1.162         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.366      0.283      0.253      0.124\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/30      11.3G      1.491     0.9714      1.152         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.383      0.291      0.266      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/30        12G      1.482     0.9507      1.142         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.388      0.284      0.262      0.129\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/30      11.7G      1.459     0.9328      1.131         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:24<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.473      0.295      0.273      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/30      11.8G      1.442     0.9074      1.118         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:21<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.496      0.309      0.294      0.147\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/30      11.7G      1.402     0.8771      1.096         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.508      0.313      0.299       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/30      11.4G      1.392     0.8626      1.095         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.515       0.32      0.301      0.148\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/30      11.7G      1.376     0.8395      1.084         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.516      0.336      0.317      0.158\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/30      11.8G      1.354     0.8184      1.076         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:24<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.515      0.335      0.311      0.157\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/30      11.2G       1.35     0.7998      1.075         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:38<00:00,  1.04s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:23<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.554      0.342      0.333      0.168\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/30      11.4G      1.321     0.7782       1.06         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.01s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:22<00:00,  1.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.559      0.342      0.337       0.17\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/30      11.3G      1.309     0.7572       1.06         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:21<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.549      0.349      0.341      0.174\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/30      11.4G      1.305     0.7483      1.056         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:21<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.575      0.348       0.35      0.179\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      25/30      11.2G      1.276     0.7232      1.044         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:20<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.566      0.357      0.354      0.181\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/30      11.9G      1.265     0.7114      1.036         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:19<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526       0.57      0.356      0.355      0.183\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/30      11.2G       1.25     0.7043      1.031         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:19<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.565      0.366      0.361      0.185\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/30      11.8G       1.25      0.699       1.03         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:20<00:00,  1.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.569      0.365      0.362      0.186\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/30      11.8G      1.257     0.7015      1.032         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:21<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526       0.58       0.36      0.363      0.186\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/30        12G       1.25     0.6932      1.032         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:37<00:00,  1.00s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [02:21<00:00,  1.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.579       0.36      0.364      0.187\n\n30 epochs completed in 1.568 hours.\nOptimizer stripped from runs/detect/yolo_bdd100k_detector/weights/last.pt, 87.6MB\nOptimizer stripped from runs/detect/yolo_bdd100k_detector/weights/best.pt, 87.6MB\n\nValidating runs/detect/yolo_bdd100k_detector/weights/best.pt...\nUltralytics 8.3.136 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 112 layers, 43,615,860 parameters, 0 gradients, 164.9 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [05:17<00:00,  2.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.568      0.358      0.361       0.19\n                  bike        578       1007      0.455      0.318      0.302      0.131\n                   bus       1242       1597       0.38      0.441       0.36      0.262\n                   car       9879     102506      0.681      0.646      0.692       0.42\n                 motor        334        452      0.409       0.19      0.194     0.0848\n                person       3220      13262       0.62      0.471      0.513      0.242\n                 rider        515        649      0.431      0.277      0.244        0.1\n         traffic light       5653      26885      0.595       0.39       0.43       0.15\n          traffic sign       8221      34908      0.595      0.467      0.486      0.245\n                 train         14         15          1          0          0          0\n                 truck       2689       4245      0.509      0.375      0.391      0.265\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 24.5ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1mruns/detect/yolo_bdd100k_detector\u001b[0m\n\nValidating trained model...\nUltralytics 8.3.136 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 112 layers, 43,615,860 parameters, 0 gradients, 164.9 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1759.0Â±582.4 MB/s, size: 79.9 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<?, ?it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [05:24<00:00,  1.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526      0.467      0.359      0.413      0.238\n                  bike        578       1007      0.453      0.319       0.38      0.186\n                   bus       1242       1597      0.379      0.442      0.395      0.306\n                   car       9879     102506      0.679      0.647      0.721      0.476\n                 motor        334        452      0.412      0.192      0.276      0.138\n                person       3220      13262      0.619      0.472      0.568      0.299\n                 rider        515        649       0.43      0.277      0.326      0.155\n         traffic light       5653      26885      0.597      0.391      0.487      0.197\n          traffic sign       8221      34908      0.594      0.469      0.538      0.304\n                 train         14         15          0          0          0          0\n                 truck       2689       4245      0.508      0.376      0.434      0.323\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 26.4ms inference, 0.0ms loss, 0.8ms postprocess per image\nResults saved to \u001b[1mruns/detect/yolo_bdd100k_detector2\u001b[0m\n\nEvaluating model performance...\nWARNING âš ï¸ 'save_hybrid' is deprecated and will be removed in in the future.\nUltralytics 8.3.136 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 112 layers, 43,615,860 parameters, 0 gradients, 164.9 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1067.9Â±275.3 MB/s, size: 43.4 KB)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/labels/val.cache... 10000 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:00<?, ?it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [02:53<00:00,  3.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all      10000     185526       0.51      0.354      0.437      0.252\n                  bike        578       1007      0.493      0.299      0.406        0.2\n                   bus       1242       1597      0.391      0.429       0.39      0.302\n                   car       9879     102506      0.783      0.644      0.753      0.505\n                 motor        334        452      0.401      0.175      0.277      0.136\n                person       3220      13262      0.698      0.477      0.615       0.33\n                 rider        515        649      0.475      0.265      0.368      0.165\n         traffic light       5653      26885      0.691      0.402      0.548      0.225\n          traffic sign       8221      34908      0.633      0.483      0.571       0.33\n                 train         14         15          0          0          0          0\n                 truck       2689       4245      0.538      0.363      0.442      0.325\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"Speed: 0.1ms preprocess, 10.8ms inference, 0.0ms loss, 0.9ms postprocess per image\nSaving runs/detect/val/predictions.json...\nResults saved to \u001b[1mruns/detect/val\u001b[0m\n\n===== BDD100K DETECTION MODEL EVALUATION =====\nmAP@0.5: 0.4369\nmAP@0.5:0.95: 0.2518\nPrecision: 0.5104\nRecall: 0.3537\nF1 Score: 0.4178\n\nPer-class AP@0.5:\n  bike: 0.4062\n  bus: 0.3898\n  car: 0.7532\n  motor: 0.2769\n  person: 0.6153\n  rider: 0.3675\n  traffic light: 0.5476\n  traffic sign: 0.5706\n  train: 0.0000\n  truck: 0.4419\nModel saved to Kaggle working directory: /kaggle/working/bdd100k_detector_best.pt\n\nTraining and evaluation complete!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!zip -r /kaggle/working/output.zip /kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T19:02:40.580065Z","iopub.execute_input":"2025-05-16T19:02:40.580466Z","iopub.status.idle":"2025-05-16T19:03:47.257431Z","shell.execute_reply.started":"2025-05-16T19:02:40.580434Z","shell.execute_reply":"2025-05-16T19:03:47.256307Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/ (stored 0%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/ (stored 0%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/F1_curve.png (deflated 10%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/R_curve.png (deflated 12%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch2_pred.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/predictions.json (deflated 79%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/P_curve.png (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/PR_curve.png (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch0_labels.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch2_labels.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch0_pred.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/confusion_matrix.png (deflated 17%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/confusion_matrix_normalized.png (deflated 15%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch1_pred.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/val/val_batch1_labels.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/ (stored 0%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/F1_curve.png (deflated 9%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/R_curve.png (deflated 11%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch2_pred.jpg (deflated 5%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/P_curve.png (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/PR_curve.png (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch0_labels.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch2_labels.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch0_pred.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/confusion_matrix.png (deflated 17%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/confusion_matrix_normalized.png (deflated 15%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch1_pred.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector2/val_batch1_labels.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/ (stored 0%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/results.csv (deflated 60%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch741.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/F1_curve.png (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/R_curve.png (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/labels_correlogram.jpg (deflated 29%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch2.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch2_pred.jpg (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/results.png (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch1.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch0.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/P_curve.png (deflated 5%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/PR_curve.png (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch740.jpg (deflated 5%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch0_labels.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/ (stored 0%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/best.pt (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/last.pt (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/epoch10.pt (deflated 41%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/epoch0.pt (deflated 37%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/weights/epoch20.pt (deflated 41%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/labels.jpg (deflated 31%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch2_labels.jpg (deflated 7%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch0_pred.jpg (deflated 8%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/train_batch742.jpg (deflated 5%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/confusion_matrix.png (deflated 17%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/confusion_matrix_normalized.png (deflated 15%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch1_pred.jpg (deflated 5%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/val_batch1_labels.jpg (deflated 6%)\n  adding: kaggle/working/vehicle_pedestrian_detection_yolo/dataset/runs/detect/yolo_bdd100k_detector/args.yaml (deflated 52%)\n","output_type":"stream"}],"execution_count":4}]}