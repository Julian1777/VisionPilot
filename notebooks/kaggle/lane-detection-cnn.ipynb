{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\nimport cv2 as cv\nimport numpy as np\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\nSCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\nCULANE_DIR = os.path.join(SCRIPT_DIR, \"dataset\", \"culane\")\nIMAGES_DIR = os.path.join(CULANE_DIR, \"images\", \"lane\")\nANNOTATIONS_DIR = os.path.join(CULANE_DIR, \"annotations\")\nMASKS_DIR = os.path.join(CULANE_DIR, \"masks\")\nMODEL_PATH = \"lane_detection_model.h5\"\n\nos.makedirs(CULANE_DIR, exist_ok=True)\nos.makedirs(MASKS_DIR, exist_ok=True)\nos.makedirs(IMAGES_DIR, exist_ok=True)\nos.makedirs(ANNOTATIONS_DIR, exist_ok=True)\n \n\nIMG_SIZE = (512, 256)\nINPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\nBATCH_SIZE = 16\nSHUFFLE_BUFFER_SIZE = 1000\nPOS_WEIGHT = 67\nSEED = 123\nEPOCHS = 30\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n\ndef iou_metric(y_true, y_pred):\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    \n    intersection = tf.reduce_sum(tf.multiply(y_true_f, y_pred_f))\n    \n    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n    \n    iou = intersection / (union + tf.keras.backend.epsilon())\n    \n    return iou\n\ndef weighted_binary_crossentropy(y_true, y_pred, pos_weight=POS_WEIGHT):\n    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n    \n    pos_loss = -y_true * tf.math.log(y_pred) * pos_weight\n    neg_loss = -(1 - y_true) * tf.math.log(1 - y_pred)\n    \n    return tf.reduce_mean(pos_loss + neg_loss)\n\ndef weighted_dice_loss(y_true, y_pred, pos_weight=POS_WEIGHT):\n    smooth = 1.0\n    \n    weighted_y_true = y_true * pos_weight\n    \n    y_true_f = tf.reshape(weighted_y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    \n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    weighted_sum = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n    \n    return 1 - (2. * intersection + smooth) / (weighted_sum + smooth)\n\ndef combined_loss(y_true, y_pred, pos_weight=POS_WEIGHT):\n    bce = weighted_binary_crossentropy(y_true, y_pred, pos_weight)\n    \n    dice = weighted_dice_loss(y_true, y_pred, pos_weight)\n    \n    return 0.5 * bce + 0.5 * dice\n\n\ndef visualize_predictions(model, dataset, num_images=3):\n    if isinstance(dataset, tf.data.Dataset):\n        for i, (images, masks) in enumerate(dataset.take(1)):\n            if i >= num_images:\n                break\n                \n            display_count = min(num_images, images.shape[0])\n            pred_masks = model.predict(images[:display_count])\n            pred_masks = (pred_masks > 0.5).astype(\"float32\")\n            \n            plt.figure(figsize=(15, 5*display_count))\n            for j in range(display_count):\n                plt.subplot(display_count, 3, j*3+1)\n                plt.imshow(images[j])\n                plt.title(\"Image\")\n                plt.axis('off')\n                \n                plt.subplot(display_count, 3, j*3+2)\n                plt.imshow(masks[j], cmap='gray')\n                plt.title(\"True Mask\")\n                plt.axis('off')\n                \n                plt.subplot(display_count, 3, j*3+3)\n                plt.imshow(pred_masks[j], cmap='gray')\n                plt.title(\"Predicted Mask\")\n                plt.axis('off')\n            \n            plt.tight_layout()\n            plt.show()\n    else:\n        if isinstance(dataset, tuple) and len(dataset) == 2:\n            images, masks = dataset\n        else:\n            print(\"Invalid input to visualize_predictions\")\n            return\n            \n        if len(images) > num_images:\n            images = images[:num_images]\n            masks = masks[:num_images]\n            \n        pred_masks = model.predict(images)\n        pred_masks = (pred_masks > 0.5).astype(\"float32\")\n        \n        plt.figure(figsize=(15, 5*num_images))\n        for j in range(num_images):\n            plt.subplot(num_images, 3, j*3+1)\n            plt.imshow(images[j])\n            plt.title(\"Image\")\n            plt.axis('off')\n            \n            plt.subplot(num_images, 3, j*3+2)\n            plt.imshow(masks[j], cmap='gray')\n            plt.title(\"True Mask\")\n            plt.axis('off')\n            \n            plt.subplot(num_images, 3, j*3+3)\n            plt.imshow(pred_masks[j], cmap='gray')\n            plt.title(\"Predicted Mask\")\n            plt.axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n\ndef load_image_mask_pair(image_path, mask_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, IMG_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=1)\n    mask = tf.image.resize(mask, IMG_SIZE)\n    mask = tf.cast(mask > 127, tf.float32)\n\n    return image, mask\n\ndef augment_data(image, mask):\n    if tf.random.uniform(()) > 0.5:\n        image = tf.image.flip_left_right(image)\n        mask = tf.image.flip_left_right(mask)\n    \n    image = tf.image.random_brightness(image, 0.2)\n    \n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    \n    image = tf.clip_by_value(image, 0.0, 1.0)\n    \n    return image, mask\n\ndef get_dataset(images_dir, masks_dir, augment=False):\n    image_paths = sorted([\n        os.path.join(images_dir, f) \n        for f in os.listdir(images_dir) \n        if f.endswith(('.jpg', '.png'))\n    ])\n    \n    mask_paths = sorted([\n        os.path.join(masks_dir, f) \n        for f in os.listdir(masks_dir) \n        if f.endswith('.png')\n    ])\n\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n    dataset = dataset.map(load_image_mask_pair, num_parallel_calls=tf.data.AUTOTUNE)\n\n    if augment:\n        dataset = dataset.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n\n    return dataset\n\ndef draw_lane_mask(anno_path, image_shape, thickness=18):\n        mask = np.zeros(image_shape[:2], dtype=np.uint8)  # H x W\n        with open(anno_path, 'r') as f:\n            lines = f.readlines()\n            for line in lines:\n                coords = list(map(float, line.strip().split()))\n                points = [(int(coords[i]), int(coords[i+1])) for i in range(0, len(coords), 2)]\n                for i in range(1, len(points)):\n                    cv.line(mask, points[i-1], points[i], color=255, thickness=thickness)\n        return mask\n\ndef process_dataset():\n\n    dataset_folders = [\n        \"driver_161_90frame\",\n        \"driver_23_30frame\",\n        \"driver_182_30frame\"\n    ]\n    \n    output_dir = CULANE_DIR\n    images_dir = IMAGES_DIR\n    annotations_dir = ANNOTATIONS_DIR\n    \n    lane_class_dir = os.path.join(images_dir)\n\n    os.makedirs(images_dir, exist_ok=True)\n    os.makedirs(annotations_dir, exist_ok=True)\n    os.makedirs(lane_class_dir, exist_ok=True)\n\n    img_count = 0\n    total_subfolder_count = 0\n    \n    for folder_name in dataset_folders:\n        base_dir = os.path.join(SCRIPT_DIR, \"dataset\", folder_name)\n        \n        if not os.path.exists(base_dir):\n            print(f\"Warning: Dataset directory not found at {base_dir}, skipping...\")\n            continue\n            \n        print(f\"\\nProcessing dataset folder: {folder_name}\")\n        \n        subfolders = [f.path for f in os.scandir(base_dir) if f.is_dir()]\n        total_subfolder_count += len(subfolders)\n        print(f\"Found {len(subfolders)} subfolders in {folder_name}\")\n        \n        for subfolder in tqdm(subfolders, desc=f\"Processing {folder_name} subfolders\"):\n            files = os.listdir(subfolder)\n            \n            img_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n            img_files = [f for f in files if any(f.endswith(ext) for ext in img_extensions)]\n            \n            for img_file in img_files:\n                img_path = os.path.join(subfolder, img_file)\n                img_basename, img_ext = os.path.splitext(img_file)\n                \n                anno_file = f\"{img_basename}.lines.txt\"\n                anno_path = os.path.join(subfolder, anno_file)\n                \n                if not os.path.exists(anno_path):\n                    continue\n                \n                img_count += 1\n                new_img_name = f\"img_{img_count}{img_ext}\"\n                new_anno_name = f\"img_{img_count}_anno.txt\"\n                \n                shutil.copy(img_path, os.path.join(lane_class_dir, new_img_name))\n                shutil.copy(anno_path, os.path.join(annotations_dir, new_anno_name))\n                \n                img = cv.imread(img_path)\n                mask = draw_lane_mask(anno_path, img.shape)\n                mask = cv.resize(mask, IMG_SIZE)\n                mask_output_path = os.path.join(MASKS_DIR, f\"img_{img_count}.png\")\n                cv.imwrite(mask_output_path, mask)\n                \n                if img_count % 100 == 0:\n                    print(f\"Processed {img_count} images so far\")\n    \n    print(f\"\\nProcessing complete. Organized {img_count} image-annotation pairs from {total_subfolder_count} subfolders across {len(dataset_folders)} datasets.\")\n    \n    copied_images = len(os.listdir(images_dir))\n    copied_annos = len(os.listdir(annotations_dir))\n    masks_count = len(os.listdir(MASKS_DIR))\n    print(f\"Files in output directories: {copied_images} images, {copied_annos} annotations, {masks_count} masks\")\n    \n    return {\n        \"base_dir\": output_dir,\n        \"images_dir\": images_dir,\n        \"annotations_dir\": annotations_dir,\n        \"masks_dir\": MASKS_DIR,\n        \"count\": img_count\n    }\n\ndef generate_masks_only():\n    print(\"Generating masks from existing images and annotations...\")\n    \n    os.makedirs(MASKS_DIR, exist_ok=True)\n    \n    image_files = [f for f in os.listdir(IMAGES_DIR) if f.endswith(('.jpg', '.png'))]\n    \n    total_images = len(image_files)\n    print(f\"Found {total_images} images. Generating masks...\")\n    \n    for i, img_file in enumerate(tqdm(image_files, desc=\"Generating masks\")):\n        img_path = os.path.join(IMAGES_DIR, img_file)\n        \n        img_basename, img_ext = os.path.splitext(img_file)\n        img_number = img_basename.split('_')[-1]\n        \n        anno_file = f\"img_{img_number}_anno.txt\"\n        anno_path = os.path.join(ANNOTATIONS_DIR, anno_file)\n        \n        if not os.path.exists(anno_path):\n            print(f\"Warning: Annotation not found for {img_file}, skipping...\")\n            continue\n        \n        img = cv.imread(img_path)\n        \n        mask = draw_lane_mask(anno_path, img.shape)\n        mask = cv.resize(mask, IMG_SIZE)\n        \n        mask_output_path = os.path.join(MASKS_DIR, f\"img_{img_number}.png\")\n        cv.imwrite(mask_output_path, mask)\n        \n        if (i + 1) % 100 == 0:\n            print(f\"Processed {i + 1}/{total_images} masks\")\n    \n    masks_count = len(os.listdir(MASKS_DIR))\n    print(f\"Mask generation complete. Created {masks_count} masks.\")\n\ndef create_lane_segmenation_model(input_shape=INPUT_SHAPE):\n    inputs = tf.keras.layers.Input(shape=input_shape)\n    \n    base_model = tf.keras.applications.EfficientNetB0(\n        input_tensor=inputs,\n        include_top=False, \n        weights='imagenet'\n    )\n    \n    backbone = tf.keras.Model(inputs=base_model.input, outputs=base_model.output, name='efficientnet_backbone')\n    backbone.trainable = False\n    \n    # Get the output of the backbone\n    x = backbone.output\n    \n    # Decoder path - Simple upsampling\n    # First upsampling: ~7×7 -> ~14×14 \n    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    \n    # Second upsampling: ~14×14 -> ~28×28\n    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    \n    # Third upsampling: ~28×28 -> ~56×56\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    \n    # Fourth upsampling: ~56×56 -> ~112×112\n    x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    \n    # Final upsampling: ~112×112 -> ~224×224\n    x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.UpSampling2D(2)(x)\n    \n    # Output layer\n    outputs = layers.Conv2D(1, 1, padding='same', activation='sigmoid')(x)\n    \n    # Create model\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model, backbone\n\nlane_images_path = os.path.join(IMAGES_DIR)\n\nimage_files = [f for f in os.listdir(lane_images_path) if f.endswith(('.jpg', '.png'))]\nannotation_files = [f for f in os.listdir(ANNOTATIONS_DIR) if f.endswith('.txt')]\n\nmasks_exist = os.path.exists(MASKS_DIR) and len(os.listdir(MASKS_DIR)) > 0\nmasks_complete = masks_exist and len(os.listdir(MASKS_DIR)) == len(image_files)\n\nprint(f\"Lane images folder: {lane_images_path} contains {len(image_files)} images.\")\nprint(f\"Annotations folder: {ANNOTATIONS_DIR} contains {len(annotation_files)} annotations.\")\n\nif masks_exist:\n    mask_files = [f for f in os.listdir(MASKS_DIR) if f.endswith('.png')]\n    print(f\"Masks folder: {MASKS_DIR} contains {len(mask_files)} masks.\")\n\nif len(image_files) > 0 and len(annotation_files) > 0:\n    if masks_complete:\n        print(f\"Dataset already processed. Found {len(image_files)} images and {len(mask_files)} masks.\")\n        processed_data = {\n            \"base_dir\": CULANE_DIR,\n            \"images_dir\": IMAGES_DIR,\n            \"annotations_dir\": ANNOTATIONS_DIR,\n            \"count\": len(image_files)\n        }\n    else:\n        print(\"Images and annotations exist, but masks are missing or incomplete.\")\n        print(\"Generating only the masks...\")\n        generate_masks_only()\n        mask_files = [f for f in os.listdir(MASKS_DIR) if f.endswith('.png')]\n        processed_data = {\n            \"base_dir\": CULANE_DIR,\n            \"images_dir\": IMAGES_DIR,\n            \"annotations_dir\": ANNOTATIONS_DIR,\n            \"count\": len(image_files)\n        }\nelse:\n    print(\"Images or annotations missing. Running complete dataset processing...\")\n    processed_data = process_dataset()\n    \n\nDATASET_PATH = processed_data[\"images_dir\"]\nprint(f\"Updated DATASET_PATH to: {DATASET_PATH}\")\n\nfull_dataset = get_dataset(IMAGES_DIR, MASKS_DIR)\n\n# 80-10-10 split\ndataset_size = processed_data[\"count\"]\ntrain_size = int(0.8 * dataset_size)\nval_size = int(0.1 * dataset_size)\ntest_size = dataset_size - train_size - val_size\n\nfull_dataset = full_dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE, reshuffle_each_iteration=False)\n\ntrain_ds = full_dataset.take(train_size)\nval_ds = full_dataset.skip(train_size).take(val_size)\ntest_ds = full_dataset.skip(train_size + val_size)\n\ntrain_ds = get_dataset(IMAGES_DIR, MASKS_DIR, augment=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\nval_ds = get_dataset(IMAGES_DIR, MASKS_DIR, augment=False).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\ntest_ds = get_dataset(IMAGES_DIR, MASKS_DIR, augment=False).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n\nprint(f\"Train dataset size: {len(train_ds)} batches\")\nprint(f\"Validation dataset size: {len(val_ds)} batches\")\nprint(f\"Test dataset size: {len(test_ds)} batches\")\n\n\n\nif os.path.exists(MODEL_PATH):\n    print(f\"Loading existing model from {MODEL_PATH}\")\n    model = load_model(\n        MODEL_PATH,\n        custom_objects={'iou_metric': iou_metric}\n    )\nelse:\n    print(\"No existing model found. Training a new model.\")\n\n    model, backbone = create_lane_segmenation_model(input_shape=INPUT_SHAPE)\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        \"best_model.h5\",\n        monitor=\"val_iou_metric\",\n        mode=\"max\",\n        save_best_only=True,\n        verbose=1,\n        save_weights_only=True\n    )\n    \n    early_stopping = EarlyStopping(\n        monitor='val_iou_metric',\n        patience=6,\n        restore_best_weights=True\n    )\n\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_iou_metric',\n        mode='max',\n        factor=0.5,\n        patience=6,\n        verbose=1,\n        min_lr=1e-6\n    )\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n        loss=lambda y_true, y_pred: combined_loss(y_true, y_pred, pos_weight=30.0), \n        metrics=[iou_metric]\n    )\n\n    print(\"Phase 1: Training with frozen backbone\")\n    history_phase1 = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        callbacks=[checkpoint, reduce_lr, early_stopping]\n    )\n\n    print(\"Phase 2: Fine-tuning backbone layers\")\n    backbone = None\n    for layer in model.layers:\n        if isinstance(layer, tf.keras.Model) and layer.name == 'efficientnet_backbone':\n            backbone = layer\n            print(f\"Found backbone model: {backbone.name}\")\n            break\n\n    if backbone is None:\n        print(\"Could not find backbone model by name, attempting to find by type...\")\n        for layer in model.layers:\n            if isinstance(layer, tf.keras.Model):\n                backbone = layer\n                print(f\"Found model layer: {backbone.name}\")\n                break\n\n    if backbone is None:\n        print(\"WARNING: No backbone found. Skipping fine-tuning phase.\")\n    else:\n        backbone.trainable = True\n        \n        print(f\"Backbone has {len(backbone.layers)} layers\")\n        \n        if len(backbone.layers) >= 100:\n            for layer in backbone.layers[:100]:\n                layer.trainable = False\n        else:\n            freeze_count = int(len(backbone.layers) * 0.3)\n            for layer in backbone.layers[:freeze_count]:\n                layer.trainable = False\n            print(f\"Froze first {freeze_count} of {len(backbone.layers)} layers\")\n\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n            loss=lambda y_true, y_pred: combined_loss(y_true, y_pred, pos_weight=20.0),\n            metrics=[iou_metric]\n        )\n\n        history_phase2 = model.fit(\n            train_ds,\n            validation_data=val_ds,\n            epochs=15,\n            callbacks=[checkpoint, reduce_lr]\n        )\n\n    combined_history = {}\n    for key in history_phase1.history:\n        combined_history[key] = history_phase1.history[key] + history_phase2.history[key]\n\n    model.save(MODEL_PATH)\n    visualize_predictions(model, val_ds)\n\n    plt.figure(figsize=(16, 6))\n\n    # Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(combined_history['loss'], label='Train Loss')\n    plt.plot(combined_history['val_loss'], label='Val Loss')\n    plt.title('Loss over Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # IoU\n    plt.subplot(1, 2, 2)\n    plt.plot(combined_history['iou_metric'], label='Train IoU')\n    plt.plot(combined_history['val_iou_metric'], label='Val IoU')\n    plt.title('IoU over Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('IoU')\n    plt.legend()\n\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}