{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOWmXOhoDqeEoD5XyYDBO/y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jr5trIZ_zkHH"},"outputs":[],"source":["import os\n","import glob\n","import json\n","import shutil\n","import random\n","import numpy as np\n","import torch\n","from google.colab import drive, files\n","from tqdm.notebook import tqdm\n","from ultralytics import YOLO\n","from datetime import datetime\n","\n","drive.mount('/content/drive')\n","\n","BASE_DIR = \"/content/traffic_sign_detection_yolo\"\n","DATASET_DIR = f\"{BASE_DIR}/dataset\"\n","ANNOTATIONS_DIR = \"/content/annotations\"  # Directory containing JSON annotations\n","IMAGES_DIR = \"/content/images\"  # Directory containing images\n","TRAIN_RATIO = 0.9\n","EPOCHS = 50\n","BATCH_SIZE = 16\n","WORKERS = 8\n","IMG_SIZE = (640, 640)\n","YOLO_MODEL_SIZE = \"yolov8l.pt\"\n","CONF_THRESHOLD = 0.15\n","\n","os.makedirs(os.path.join(DATASET_DIR, \"images\", \"train\"), exist_ok=True)\n","os.makedirs(os.path.join(DATASET_DIR, \"images\", \"val\"), exist_ok=True)\n","os.makedirs(os.path.join(DATASET_DIR, \"labels\", \"train\"), exist_ok=True)\n","os.makedirs(os.path.join(DATASET_DIR, \"labels\", \"val\"), exist_ok=True)\n","\n","print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","    device = '0'\n","    os.environ['CUDA_MODULE_LOADING'] = 'LAZY'\n","    torch.backends.cudnn.benchmark = True\n","    torch.backends.cuda.matmul.allow_tf32 = True\n","    torch.backends.cudnn.allow_tf32 = True\n","else:\n","    print(\"No CUDA devices available, using CPU\")\n","    device = 'cpu'\n","\n","def load_class_mapping():\n","    \"\"\"Create a mapping from sign labels to class IDs\"\"\"\n","    unique_labels = set()\n","\n","    print(\"Scanning for unique labels...\")\n","    json_files = glob.glob(os.path.join(ANNOTATIONS_DIR, \"*.json\"))\n","    for json_file in tqdm(json_files):\n","        with open(json_file, 'r') as f:\n","            data = json.load(f)\n","            for obj in data.get(\"objects\", []):\n","                label = obj.get(\"label\")\n","                if label and label != \"other-sign\":\n","                    unique_labels.add(label)\n","\n","    sorted_labels = sorted(list(unique_labels))\n","    label_to_id = {label: i for i, label in enumerate(sorted_labels)}\n","\n","    print(f\"Found {len(sorted_labels)} unique traffic sign classes\")\n","    return label_to_id, sorted_labels\n","\n","def convert_annotations(json_file, label_to_id):\n","    \"\"\"Convert a JSON annotation to YOLO format\"\"\"\n","    try:\n","        with open(json_file, 'r') as f:\n","            data = json.load(f)\n","\n","        img_width = data.get(\"width\", 0)\n","        img_height = data.get(\"height\", 0)\n","\n","        if img_width <= 0 or img_height <= 0:\n","            return None\n","\n","        yolo_annotations = []\n","\n","        for obj in data.get(\"objects\", []):\n","            label = obj.get(\"label\")\n","            if label == \"other-sign\" or label not in label_to_id:\n","                continue\n","\n","            bbox = obj.get(\"bbox\", {})\n","            if not all(k in bbox for k in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]):\n","                continue\n","\n","            xmin = bbox[\"xmin\"]\n","            ymin = bbox[\"ymin\"]\n","            xmax = bbox[\"xmax\"]\n","            ymax = bbox[\"ymax\"]\n","\n","            x_center = (xmin + xmax) / 2 / img_width\n","            y_center = (ymin + ymax) / 2 / img_height\n","            width = (xmax - xmin) / img_width\n","            height = (ymax - ymin) / img_height\n","\n","            if not all(0 <= val <= 1 for val in [x_center, y_center, width, height]):\n","                continue\n","\n","            class_id = label_to_id[label]\n","            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n","\n","        return yolo_annotations\n","    except Exception as e:\n","        print(f\"Error processing {json_file}: {e}\")\n","        return None\n","\n","def prepare_dataset():\n","    print(\"Loading class mappings...\")\n","    label_to_id, class_names = load_class_mapping()\n","\n","    print(\"Finding all annotation files...\")\n","    json_files = glob.glob(os.path.join(ANNOTATIONS_DIR, \"*.json\"))\n","\n","    file_pairs = []\n","    for json_file in json_files:\n","        base_name = os.path.basename(json_file)\n","        image_id = os.path.splitext(base_name)[0]\n","\n","        for ext in ['.jpg', '.jpeg', '.png']:\n","            img_path = os.path.join(IMAGES_DIR, f\"{image_id}{ext}\")\n","            if os.path.exists(img_path):\n","                file_pairs.append((json_file, img_path))\n","                break\n","\n","    print(f\"Found {len(file_pairs)} image-annotation pairs\")\n","\n","    random.seed(42)\n","    random.shuffle(file_pairs)\n","\n","    split_idx = int(len(file_pairs) * TRAIN_RATIO)\n","    train_pairs = file_pairs[:split_idx]\n","    val_pairs = file_pairs[split_idx:]\n","\n","    print(f\"Split dataset: {len(train_pairs)} training, {len(val_pairs)} validation\")\n","\n","    print(\"Processing training set...\")\n","    for json_file, img_path in tqdm(train_pairs):\n","        base_name = os.path.basename(json_file)\n","        image_id = os.path.splitext(base_name)[0]\n","\n","        img_ext = os.path.splitext(img_path)[1]\n","        dest_img = os.path.join(DATASET_DIR, \"images\", \"train\", f\"{image_id}{img_ext}\")\n","        shutil.copy2(img_path, dest_img)\n","\n","        yolo_annotations = convert_annotations(json_file, label_to_id)\n","        if yolo_annotations:\n","            label_path = os.path.join(DATASET_DIR, \"labels\", \"train\", f\"{image_id}.txt\")\n","            with open(label_path, 'w') as f:\n","                f.write(\"\\n\".join(yolo_annotations))\n","\n","    print(\"Processing validation set...\")\n","    for json_file, img_path in tqdm(val_pairs):\n","        base_name = os.path.basename(json_file)\n","        image_id = os.path.splitext(base_name)[0]\n","\n","        img_ext = os.path.splitext(img_path)[1]\n","        dest_img = os.path.join(DATASET_DIR, \"images\", \"val\", f\"{image_id}{img_ext}\")\n","        shutil.copy2(img_path, dest_img)\n","\n","        yolo_annotations = convert_annotations(json_file, label_to_id)\n","        if yolo_annotations:\n","            label_path = os.path.join(DATASET_DIR, \"labels\", \"val\", f\"{image_id}.txt\")\n","            with open(label_path, 'w') as f:\n","                f.write(\"\\n\".join(yolo_annotations))\n","\n","    print(\"Creating dataset.yaml...\")\n","    dataset_yaml_path = os.path.join(DATASET_DIR, \"dataset.yaml\")\n","    with open(dataset_yaml_path, \"w\") as f:\n","        f.write(f\"train: ./images/train\\n\")\n","        f.write(f\"val: ./images/val\\n\")\n","        f.write(f\"nc: {len(class_names)}\\n\")\n","        f.write(f\"names: {class_names}\\n\")\n","\n","    train_imgs = glob.glob(os.path.join(DATASET_DIR, \"images\", \"train\", \"*.*\"))\n","    val_imgs = glob.glob(os.path.join(DATASET_DIR, \"images\", \"val\", \"*.*\"))\n","    train_labels = glob.glob(os.path.join(DATASET_DIR, \"labels\", \"train\", \"*.txt\"))\n","    val_labels = glob.glob(os.path.join(DATASET_DIR, \"labels\", \"val\", \"*.txt\"))\n","\n","    print(\"\\nDataset prepared:\")\n","    print(f\"  Training images: {len(train_imgs)}\")\n","    print(f\"  Training labels: {len(train_labels)}\")\n","    print(f\"  Validation images: {len(val_imgs)}\")\n","    print(f\"  Validation labels: {len(val_labels)}\")\n","    print(f\"  Classes: {len(class_names)}\")\n","\n","    return dataset_yaml_path\n","\n","def train_model(dataset_yaml_path):\n","    print(\"\\nInitializing YOLOv8 model...\")\n","    try:\n","        model = YOLO(YOLO_MODEL_SIZE)\n","        print(\"Model loaded successfully\")\n","    except Exception as e:\n","        print(f\"Error loading model: {e}\")\n","        print(\"Downloading model using torch hub...\")\n","        torch.hub.load('ultralytics/yolov8', 'yolov8l', pretrained=True)\n","        model = YOLO(YOLO_MODEL_SIZE)\n","\n","    from IPython.display import display, Javascript\n","    def keep_alive():\n","        display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"Clicking connect button\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","        '''))\n","\n","    print(\"\\nStarting training...\")\n","    keep_alive()\n","\n","    os.chdir(DATASET_DIR)\n","\n","    results = model.train(\n","        data=dataset_yaml_path,\n","        epochs=EPOCHS,\n","        workers=WORKERS,\n","        imgsz=IMG_SIZE,\n","        batch=BATCH_SIZE,\n","        name='yolo_traffic_sign_detector',\n","        patience=15,\n","        save=True,\n","        device=device,\n","        cache=False,\n","        amp=True,\n","        rect=True,\n","        plots=True,\n","        augment=True,\n","        close_mosaic=10,\n","        overlap_mask=True,\n","        cos_lr=True,\n","        pretrained=True,\n","        seed=42,\n","        profile=True,\n","        verbose=True,\n","        mosaic=0.8,\n","        mixup=0.1,\n","        copy_paste=0.1,\n","        degrees=10.0,\n","        scale=0.5,\n","        save_period=10\n","    )\n","\n","    print(\"\\nValidating trained model...\")\n","    metrics = model.val(\n","        data=dataset_yaml_path,\n","        conf=CONF_THRESHOLD\n","    )\n","\n","    best_model_path = os.path.join(\"runs\", \"detect\", \"yolo_traffic_sign_detector\", \"weights\", \"best.pt\")\n","\n","    print(\"\\nEvaluating model performance...\")\n","    evaluate_detection_model(\n","        model_path=best_model_path,\n","        data_yaml=dataset_yaml_path,\n","        conf_threshold=CONF_THRESHOLD,\n","        iou_threshold=0.5,\n","        save_dir=\"/content/detection_metrics\"\n","    )\n","\n","    try:\n","        drive_model_path = \"/content/drive/MyDrive/traffic_sign_detection/best_model.pt\"\n","        os.makedirs(os.path.dirname(drive_model_path), exist_ok=True)\n","        os.system(f\"cp {best_model_path} {drive_model_path}\")\n","        print(f\"Model saved to Google Drive at: {drive_model_path}\")\n","    except Exception as e:\n","        print(f\"Could not save to Drive: {e}\")\n","\n","    files.download(best_model_path)\n","\n","    results_img = f\"runs/detect/yolo_traffic_sign_detector/results.png\"\n","    confusion_matrix = f\"runs/detect/yolo_traffic_sign_detector/confusion_matrix.png\"\n","\n","    if os.path.exists(results_img):\n","        files.download(results_img)\n","    if os.path.exists(confusion_matrix):\n","        files.download(confusion_matrix)\n","\n","    print(\"\\nTraining and evaluation complete!\")\n","\n","def evaluate_detection_model(model_path, data_yaml, conf_threshold=0.15, iou_threshold=0.5, save_dir=\"metrics\"):\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    model = YOLO(model_path)\n","\n","    metrics = model.val(\n","        data=data_yaml,\n","        conf=conf_threshold,\n","        iou=iou_threshold,\n","        verbose=True,\n","        save_json=True,\n","        save_hybrid=True,\n","        plots=True\n","    )\n","\n","    results = {\n","        \"mAP50\": float(metrics.box.map50),\n","        \"mAP50-95\": float(metrics.box.map),\n","        \"precision\": float(metrics.box.mp),\n","        \"recall\": float(metrics.box.mr),\n","        \"f1\": float(2 * metrics.box.mp * metrics.box.mr / (metrics.box.mp + metrics.box.mr + 1e-10)),\n","        \"conf_threshold\": conf_threshold,\n","        \"iou_threshold\": iou_threshold,\n","        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    }\n","\n","    per_class_ap = {}\n","    if hasattr(metrics.box, 'ap_class_index') and hasattr(metrics.box, 'ap50'):\n","        class_names = model.names\n","        for i, class_idx in enumerate(metrics.box.ap_class_index):\n","            class_name = class_names[int(class_idx)]\n","            per_class_ap[class_name] = float(metrics.box.ap50[i])\n","        results[\"per_class_ap50\"] = per_class_ap\n","\n","    with open(os.path.join(save_dir, f\"metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"), 'w') as f:\n","        json.dump(results, f, indent=4)\n","\n","    print(\"\\n===== DETECTION MODEL EVALUATION =====\")\n","    print(f\"mAP@0.5: {results['mAP50']:.4f}\")\n","    print(f\"mAP@0.5:0.95: {results['mAP50-95']:.4f}\")\n","    print(f\"Precision: {results['precision']:.4f}\")\n","    print(f\"Recall: {results['recall']:.4f}\")\n","    print(f\"F1 Score: {results['f1']:.4f}\")\n","\n","    if \"per_class_ap50\" in results:\n","        print(\"\\nPer-class AP@0.5:\")\n","        for class_name, ap in results[\"per_class_ap50\"].items():\n","            print(f\"  {class_name}: {ap:.4f}\")\n","\n","    return results\n","\n","if __name__ == \"__main__\":\n","    dataset_yaml_path = prepare_dataset()\n","    train_model(dataset_yaml_path)"]}]}